{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq RNN using Keras\n",
    "\n",
    "<p style=\"text-align:justify;\">This project is simply a walk through the code I found on the [Keras's blog](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html). The goal is to use LSTM to translate a sentence from English to French. The difficulty of this assignement is the sizes of the input and outpu data. Indeed, we have various unknowned sizes for the input sentences and the output is not likely to have the same size as the input.</p>\n",
    "\n",
    "<div class='alert alert-info'>\"the cat sat on the mat\" -> [Seq2Seq model] -> \"le chat etait assis sur le tapis\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'datas/fra.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start reading the datas and putting it inside numpy 3 dimensionnal vector of dimension (m, $T_{x}$, nbr_chars).\n",
    "\n",
    "m: The number of examples<br>\n",
    "$T_{x}$: The number of characters in the sentence. In this case, it is the nbr of chars in the longest sentence<br>\n",
    "nbr_chars: The number of characters in the dictionnary for each language\n",
    "\n",
    "<p style=\"text-align:justify;\">It is interesting to note that we added \\t at the beginning of each output datas and \\n at the end of each output datas. The goal is to tell the algorithm where to start and where to stop. \\t is given as the first character, then the RNN needs to predict the next one until \\n.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 94\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for line in lines[:min(num_samples, len(lines)-1)]:\n",
    "    input_text, target_text = line.split(\"\\t\")\n",
    "    target_text = \"\\t\"+target_text+\"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">The decoder output data is at T+1 compare to decoder input data. This is made like that so the RNN learns to predict the next character given the context of the encoder RNN.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">RNN models need a lot of computation power to be trained. In this example, running 100 epochs on a 10000 sentences dataset took 20 seconds for each epochs. The total computation took around 33 minutes on a computer using only the CPU.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.9210 - val_loss: 0.9688\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.7362 - val_loss: 0.8026\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.6259 - val_loss: 0.7149\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.5692 - val_loss: 0.6640\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.5300 - val_loss: 0.6273\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.4984 - val_loss: 0.6058\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.4708 - val_loss: 0.5784\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.4485 - val_loss: 0.5529\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.4276 - val_loss: 0.5435\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.4098 - val_loss: 0.5267\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3942 - val_loss: 0.5171\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3795 - val_loss: 0.5194\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3661 - val_loss: 0.5035\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3536 - val_loss: 0.4938\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3418 - val_loss: 0.4843\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3302 - val_loss: 0.4840\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3196 - val_loss: 0.4770\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3091 - val_loss: 0.4746\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2995 - val_loss: 0.4734\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2899 - val_loss: 0.4694\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2811 - val_loss: 0.4700\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2723 - val_loss: 0.4716\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2641 - val_loss: 0.4709\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2568 - val_loss: 0.4703\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.2490 - val_loss: 0.4812\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2413 - val_loss: 0.4732\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2349 - val_loss: 0.4740\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2280 - val_loss: 0.4780\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2218 - val_loss: 0.4797\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2158 - val_loss: 0.4828\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2094 - val_loss: 0.4964\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2040 - val_loss: 0.4934\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1987 - val_loss: 0.4968\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1931 - val_loss: 0.5024\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1883 - val_loss: 0.5041\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1837 - val_loss: 0.5080\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1792 - val_loss: 0.5112\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1750 - val_loss: 0.5172\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1701 - val_loss: 0.5217\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1662 - val_loss: 0.5304\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1623 - val_loss: 0.5285\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1586 - val_loss: 0.5394\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1546 - val_loss: 0.5385\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1511 - val_loss: 0.5443\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1479 - val_loss: 0.5569\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1441 - val_loss: 0.5521\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1414 - val_loss: 0.5558\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1385 - val_loss: 0.5608\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1354 - val_loss: 0.5701\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1325 - val_loss: 0.5703\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1295 - val_loss: 0.5723\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1274 - val_loss: 0.5762\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1245 - val_loss: 0.5899\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1220 - val_loss: 0.5938\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1195 - val_loss: 0.5929\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1174 - val_loss: 0.6033\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1150 - val_loss: 0.6020\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1128 - val_loss: 0.6096\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1108 - val_loss: 0.6154\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1092 - val_loss: 0.6143\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1068 - val_loss: 0.6207\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1048 - val_loss: 0.6267\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1031 - val_loss: 0.6347\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1011 - val_loss: 0.6393\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0997 - val_loss: 0.6381\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0977 - val_loss: 0.6483\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0962 - val_loss: 0.6430\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0942 - val_loss: 0.6535\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0930 - val_loss: 0.6593\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0914 - val_loss: 0.6678\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0897 - val_loss: 0.6752\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 28s 4ms/step - loss: 0.0883 - val_loss: 0.6731\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 27s 3ms/step - loss: 0.0869 - val_loss: 0.6692\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0856 - val_loss: 0.6783\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0839 - val_loss: 0.6960\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0833 - val_loss: 0.6860\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0814 - val_loss: 0.6976\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0801 - val_loss: 0.6969\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0794 - val_loss: 0.7001\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0779 - val_loss: 0.7092\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0767 - val_loss: 0.7061\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0757 - val_loss: 0.7130\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0742 - val_loss: 0.7193\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0736 - val_loss: 0.7207\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0725 - val_loss: 0.7252\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.0713 - val_loss: 0.7240\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0705 - val_loss: 0.7306\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0693 - val_loss: 0.7325\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0684 - val_loss: 0.7417\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0669 - val_loss: 0.7349\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0662 - val_loss: 0.7474\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0654 - val_loss: 0.7468\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0647 - val_loss: 0.7513\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0635 - val_loss: 0.7540\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0629 - val_loss: 0.7526\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0619 - val_loss: 0.7610\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0607 - val_loss: 0.7667\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.0603 - val_loss: 0.7710\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0597 - val_loss: 0.7755\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.0586 - val_loss: 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cnqv2027\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\network.py:872: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it is going to work:\n",
    "1. Encode input and retrieve initial decoder state\n",
    "2. Run one step of decoder with this initial state\n",
    "   and a \"start of sequence\" token as target.\n",
    "   Output will be the next target token\n",
    "3. Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sampling model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict([(i, char) for i, char in enumerate(input_characters)])\n",
    "reverse_target_char_index = dict([(i, char) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1,num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Courez !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Courez !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivez.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivez.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuivez.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je cross.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaye.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: T'as capté ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombé.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombé.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je sais.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu le contrôle.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: J'ai froid.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis impulsive.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis impulsive.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Écoutez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est hors de question !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vrai ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: On essaye.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fantastique !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Sois danssable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois gentil.\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentil !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Dégage !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-le tomber !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    #seq: seq+1 to keep the shape of (1, 16, 71) not (16, 71)\n",
    "    input_seq = encoder_input_data[seq_index: seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
